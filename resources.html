<html>
<head>
<link rel="stylesheet" href="./style.css" type="text/css"/>
<title>The International Society of Music Information Retrieval</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48096804-1', 'auto');
  ga('send', 'pageview');

</script>
</head>

<body>
<div id="container">
<div id="header">
<h1>
<a href="http://ismir.net">
  <img src="img/ismir_04.png" alt="The International Society of Music Information Retrieval"
       style="width:300px;margin-left:-48px; margin-bottom:-100px"></a>
</h1>
</div>
<div id="spacer"><img src="img/barstaff.png" alt="staff2circuit" style="width:900px"></div>
<div id="content-container">
<div id="navigation">
<ul>
  <li><a href="index.html">Home</a></li>
  <li><a href="conferences.html">Previous Conferences</a></li>
  <li><a href="http://www.informatik.uni-trier.de/~ley/db/conf/ismir/index.html" target="_blank">Proceedings</a></li>
  <li><a href="resources.html">Resources</a></li>
  <li><a href="society.html">About the Society</a></li>
  <li><a href="stats.html">Membership and Paper Statistics</a></li>
  <li><a href="wimir.html">Women in MIR</a></li>
  <li><a href="membership.html">Membership</a></li>
  <li><a href="contact.html">Contact</a></li>
</ul>
</div>

<div id="content">
  <h2 id="resources">Resources</h2>
  <p>
  <ul>
  <li><a href="#research-centers">Research Centers</a></li>
  <li><a href="#related">Related Conferences and Journals</a></li>
  <li><a href="#educational-materials">Educational Materials</a></li>
  <li><a href="#software-tools">Software Tools</a></li>
  <li><a href="#datasets">Datasets</a></li>
  </ul>
  </br>
  </p>

  <h3>Overview</h3>
  <p>The following is a non-exhaustive list of content relevant to the ISMIR community,
  submitted by its members. Keep in mind that it is provided in good faith and a result
  of user submissions.
  Therefore, if something should (or shouldn't) be here, let us know.
  <ul>
  <li><a href="https://docs.google.com/forms/d/1vYIfoRBI0slDL2ep_uuAweuLIHSU2lY6o8qh-XPMN5I/viewform" target="_blank">Contributions</a></li>
  <li><a href="mailto:webmaster@ismir.net">Corrections</a></li>
  </ul>
  </br>
  </p>

  <h3 id="research-centers">Research Centers</h3>
  <table style="width:100%">
  <tr>
    <td><b>Group / Description</b></td>
    <td><b>Location</b></td>
  </tr>
  <tr>
    <td><a href="http://marl.smusic.nyu.edu">Music and Audio Research Laboratory at New York University</a>
    </br>Doctoral and masters programs in music technology in the heart of New York City. Main research areas
       include MIR, Immersive Audio, Music Cognition and Interactive Systems.</li>
    </td>
    <td>US</td>
  </tr>
  <tr>
    <td><a href="http://mir.dei.uc.pt/">MIR Group at the University of Coimbra</a></td>
    <td>PT</td>
  </tr>
  <tr>
    <td><a href="http://www.ifs.tuwien.ac.at/mir">Music Information Retrieval Lab at Vienna University of Technology</a></td>
    <td>AT</td>
  </tr>
  <tr>
    <td><a href="http://www.gtcmt.gatech.edu/">Music Technology at Georgia Tech</a></td>
    <td>US</td>
  </tr>
  <tr>
    <td><a href="http://mi.soi.city.ac.uk/">Music Informatics Research Group at City University London</a></td>
    <td>UK</td>
  </tr>
  <tr>
    <td><a href="http://www.algomus.fr/">Algomus</a>
    </br>Research lab on computational music analysis, focusing on large-scale analysis of scores.</td>
    <td>FR</td>
  </tr>
  <tr>
    <td><a href="http://www.cp.jku.at">Department of Computational Perception of the Johannes Kepler University Linz</a> </td>
    <td>AT</td>
  </tr>
  <tr>
    <td><a href="http://c4dm.eecs.qmul.ac.uk/">Centre for Digital Music (C4DM) at Queen Mary University of London</a>
    </br>C4DM is a world-leading multidisciplinary research group in the field
    of music and audio technology. Research ranges from record/replay equipment to the
    simulation and synthesis of instruments and voices, acoustic spaces, music
    understanding, delivery and retrieval. With a strong focus on making innovation
    usable, we are ideally placed to work with industry leaders in forging new business
    models for the music industry.</td>
    <td>UK</td>
  </tr>
  <tr>
    <td><a href="http://www.create.aau.dk/audio/">Audio Analysis Lab at Aalborg University</a></td>
    <td>DK</td>
  </tr>
  <tr>
    <td><a href="http://sig-ma.de/">Special Interest Group on Music Analysis</a></td>
    <td>DE</td>
  </tr>
  <tr>
    <td><a href="http://mtg.upf.edu/">Music Technology Group at UPF</a> </br>
    The Music Technology Group (MTG) of the Universitat Pompeu Fabra in
    Barcelona is specialized in sound and music computing. With more than 50
    researchers, the MTG carries out research on topics such as audio signal
    processing, sound and music description, musical interfaces, sound and music
    communities and performance modeling among others.
    </td>
    <td>ES</td>
  </tr>
  <tr>
    <td><a href="http://www.ofai.at/research/impml/index.html">Intelligent Music Processing Group at the Austrian Research Institute for Artificial Intelligence</a></td>
    <td>AT</td>
  </tr>
  <tr>
    <td><a href="http://music.ece.drexel.edu">Music and Entertainment Technology Laboratory (MET-lab) at Drexel</a></br>
    The Music and Entertainment Technology Laboratory (MET-lab) is devoted
    to research in digital media technologies that will shape the future of entertainment.
    MET-lab's primary research focus encompasses several areas: music information
    retrieval, music production technology, new musical interfaces, and musical
    humanoid robotics. The lab also emphasizes K-12 outreach and hosts Summer Music
    Technology, a one-week experience based educational curriculum for high school students.</td>
    <td>US</td>
  </tr>
  <tr>
    <td><a href="http://mue.music.miami.edu/">Music Engineering at the University of Miami</a></td>
    <td>US</td>
  </tr>
  <tr>
    <td><a href="http://www.cirmmt.org/">The Centre of Interdisciplinary Research in Music Media and Technology (CIRMMT) at McGill</a></td>
    <td>CA</td>
  </tr>
  <tr>
    <td><a href="http://www.ircam.fr/">Institut de Recherche et Coordination Acoustique / Musique (IRCAM)</a></td>
    <td>FR</td>
  </tr>
  <tr>
    <td><a href="http://www.audiolabs-erlangen.de/">International Audio Laboratories Erlangen</a></br>
    The group <a href="http://www.audiolabs-erlangen.de/meinard/">Semantic Audio Processing</a>
    deals with the development of techniques and tools for analyzing, structuring, retrieving,
    navigating, and presenting music-related audio signals and other time-dependent multimedia data streams.</td>
    <td>DE</td>
  </tr>
  <tr>
    <td><a href="http://www.atic.uma.es/index_atic.html">Application of Information and Communication Technologies Research Group</a></td>
    <td>ES</td>
  </tr>
  </table>
  </br>

<h3 id="related">Related Conferences and Journals</h3>
  <table style="width:100%">
  <tr>
    <td><b>Conferences</b></td>
  </tr>
  <tr>
    <td><a href="http://icassp2015.org/">International Conference on Acoustics, Speech,
    and Signal Processing (ICASSP)</a></td>
  </tr>
  <tr>
    <td><a href="http://www.computermusic.org/">International Computer Music Association</a></td>
  </tr>
  <tr>
    <td><a href="http://smcnetwork.org/">Sound and Music Computing (SMC)</a></td>
  </tr>
  <tr>
    <td><a href="http://nips.cc/">Neural Information Processing Systems (NIPS)</a></td>
  </tr>
  <tr>
    <td><b>Journals</b></td>
  </tr>
  <tr>
    <td><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6570655">
    IEEE / ACM Transactions on Audio, Speech, and Language Processing (TASLP)</a></td>
  </tr>
  <tr>
    <td><a href="http://ucpressjournals.com/journal.php?j=mp">Music Perception</a></td>
  </tr>
  <tr>
    <td><a href="http://www.tandfonline.com/toc/nnmr20/current">Journal of New Music Research</a></td>
  </tr>
  </table>
  </br>


  <h3 id="educational-materials">Educational Materials</h3>
  <table style="width:100%">
  <tr>
    <td><b>Description</b></td>
    <td><b>Link</b></td>
  </tr>
  <tr>
    <td>Matlab code for feature extraction, pitch tracking, key detection, onset detection,
        and links to data sets and MIR-related software projects.
    </td>
    <td>[<a href="http://www.AudioContentAnalysis.org">link</a>]</td>
  </tr>
  <tr>
    <td>A centralized collection of teaching resources related to Music Information
        Retrieval. It is addressed to teachers and students interested on these
        technologies from an educational point of view. Current resources include
        the following: a list of courses related to MIR in different levels, institutions
        and countries; a collaborative (small) list of teaching materials, such
        as exercises, musical examples, code; and a list of datasets and reference annotations.
    </td>
    <td>[<a href="">link</a>]</td>
  </tr>
  </table>
  </br>


  <h3 id="software-tools">Software Tools</h3>
  <table style="width:100%">
  <tr>
    <td><b>Description</b></td>
    <td><b>Link</b></td>
  </tr>
  <tr>
    <td>jMIR is an open-source software suite implemented in Java for use in
        music classification research. It can be used to study music in both audio
        and symbolic formats, as well as mine cultural information from the web
        and manage music collections. jMIR includes software for extracting features,
        applying machine learning algorithms, mining metadata and analyzing metadata.
    </td>
    <td>[<a href="http://jmir.sourceforge.net">link</a>] </td>
  </tr>
  <tr>
    <td>Essentia is an open-source C++ library for audio analysis and audio-based
        music information retrieval released under the Affero GPLv3 license
        (also available under proprietary license upon request) which has been
        developed by the Music Technology Group in Universitat Pompeu Fabra.
        Essentia was awarded with the Open-Source Competition of ACM Multimedia in 2013.
    </td>
    <td>[<a href="http://essentia.upf.edu/">link</a>]</td>
  </tr>
  <tr>
    <td>LibRosa is a python package for music and audio processing.
    </td>
    <td>[<a href="https://github.com/bmcfee/librosa/">link</a>]</td>
  </tr>
  <tr>
    <td>Time-scale Modification (TMS) Toolbox - MATLAB implementations of
    various classical time-scale modification algorithms like OLA, WSOLA, and the
    phase vocoder, among more recent advances.
    </td>
    <td>[<a href="http://www.audiolabs-erlangen.de/resources/MIR/TSMtoolbox/">link</a>]</td>
  </tr>
  <tr>
    <td>Chroma Toolbox - MATLAB implementations for extracting various types of
    novel pitch-based and chroma-based audio features.
    </td>
    <td>[<a href="http://resources.mpi-inf.mpg.de/MIR/chromatoolbox/">link</a>]</td>
  </tr>
  <tr>
    <td>Tempogram Toolbox - MATLAB implementations for extracting various types
    of recently proposed tempo and pulse related audio representations.
    </td>
    <td>[<a href="http://resources.mpi-inf.mpg.de/MIR/tempogramtoolbox/">link</a>]</td>
  </tr>
  <tr>
    <td>Similarity Matrix (SM) Toolbox - MATLAB implementations for computing
    and enhancing similarity matrices in various ways.
    </td>
    <td>[<a href="http://www.audiolabs-erlangen.de/resources/MIR/SMtoolbox/">link</a>]</td>
  </tr>
  </table>
  </br>


   <h3 id="datasets">Datasets</h3>
   <table style="width:100%">
  <tr>
    <td><b>Description</b></td>
    <td><b>Link</b></td>
  </tr>
  <tr>
    <td>Primary resource for the Million Song Dataset</td>
    <td>[<a href="http://labrosa.ee.columbia.edu/millionsong/">link</a>]</td>
  </tr>
  <tr>
    <td>Various datasets hosted by the MTG</td>
    <td>[<a href="http://mtg.upf.edu/download/datasets">link</a>]</td>
  </tr>
  <tr>
    <td>Alternative resource for the Million Song Dataset: Feature Sets and Benchmark splits.
    </td>
    <td>[<a href="http://www.ifs.tuwien.ac.at/mir/msd/">link</a>]</td>
  </tr>
  <tr>
    <td>Home page of the McGill Billboard annotations, containing time-aligned
        chord annotations and structural analyses of a randomised sample of over
        1000 songs from the American Billboard Hot 100 charts between 1958 and 1991.</td>
    <td>[<a href="http://ddmal.music.mcgill.ca/billboard">link</a>] </td>
  </tr>
  <tr>
    <td>A dataset of MusicXML excerpts and corresponding Schenkerian analyses in
        a computer-readable format.</td>
    <td>[<a href="http://www.cs.rhodes.edu/~kirlinp/schenker/">link</a>]</td>
  </tr>
  <tr>
    <td>Reference data for computational music analysis. Now contains a dataset of
    ground truth structures for fugues.</td>
    <td>[<a href="http://algomus.fr/truth/">link</a>]</td>
  </tr>
  <tr>
    <td>The "Million Musical Tweets Dataset" (MMTD) contains listening histories
    inferred from microblogs. Each listening event identified via twitter-id and
    user-id is annotated with temporal (date, time, weekday, timezone), spatial
    (longitude, latitude, continent, country, county, state, city), and contextual
    (information on the country) information. In addition, pointers to artist and
    track are provided as a matter of course.</td>
    <td>[<a href="http://www.cp.jku.at/datasets/MMTD/">link</a>]</td>
  </tr>
  <tr>
    <td>The "MusicMicro 11.11-09.12" data set contains listening histories inferred
    from microblogs. Each listening event identified via twitter-id and user-id is
    annotated with temporal (month and weekday) and spatial (longitude, latitude,
    country, and city) information. In addition, pointers to artist and track
    are provided as a matter of course.</td>
    <td>[<a href="http://www.cp.jku.at/datasets/musicmicro/index.html">link</a>] </td>
  </tr>
  <tr>
    <td>The MusiClef 2012 - Multimodal Music Data Set provides editorial metadata,
    various audio features, user tags, web pages, and expert labels on a set of 1355
    popular songs. It was used in the MusiClef 2012
    <a href="http://multimediaeval.org/mediaeval2012/newtasks/music2012/index.html">Evaluation Campaign</a>.</td>
    <td>[<a href="http://www.cp.jku.at/datasets/musiclef/index.html">link</a>]</td>
  </tr>
  <tr>
    <td>Index of contents of the GTZAN dataset.</td>
    <td>[<a href="http://imi.aau.dk/~bst/software/GTZANindex.txt">link</a>] </td>
  </tr>
  <tr>
    <td>List of replicas found in the Latin Music Database.</td>
    <td>[<a href="http://media.aau.dk/null_space_pursuits/2014/02/faults-in-the-latin-music-database.html">link</a>]</td>
  </tr>
  <tr>
    <td>List of replicas found in the Ballroom dataset.</td>
    <td>[<a href="http://media.aau.dk/null_space_pursuits/2014/01/ballroom-dataset.html">link</a>]</td>
  </tr>
  <tr>
    <td>Saarland Music Data (SMD) - SMD supplies free music recordings of Western
    classical music (SMD Western Music) as well as MIDI-audio pairs (SMD MIDI-Audio Piano Music),
    which have been generated by using hybrid acoustic / digital pianos (Disklavier).</td>
    <td>[<a href="http://resources.mpi-inf.mpg.de/SMD/">link</a>]</td>
  </tr>
  <tr>
    <td>Music Synchronization for RWC Music Database (Classical Music) - Website for
    synchronized MIDI-audio pairs obtained from the synchronization procedure. </td>
    <td>[<a href="http://resources.mpi-inf.mpg.de/MIR/SyncRWC60/">link</a>]</td>
  </tr>

  </table>
  </br>

</div>

<div class="footer-container">
  <div class="div-right">
  <ul class="footer">
    <li>Copyright &copy; ISMIR, 2016</li>
    <li><a href="https://github.com/ismir-net">
      <img src="img/GitHub-Mark-32px.png" alt="The International Society of Music Information Retrieval"></a></li>
  </ul></div>
</div>

</div>
</div>
</body>
</html>
