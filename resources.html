<html>
<head>
<link rel="stylesheet" href="./style.css" type="text/css"/>
</head>

<body>
<div id="container">
<div id="header">
<h1>
ISMIR
</h1>
The International Society for Music Information Retrieval
</div>
<div id="spacer"></div>
<div id="content-container">
<div id="navigation">
<ul>
  <li><a href="index.html">Home</a></li>
  <li><a href="conferences.html">Previous Conferences</a></li>
  <li><a href="http://www.informatik.uni-trier.de/~ley/db/conf/ismir/index.html" target="_blank">Proceedings</a></li>
  <li><a href="resources.html">Resources</a></li>
  <li><a href="about.html">About</a></li>
  <li><a href="contact.html">Contact</a></li>
</ul>
</div>

<div id="content">
  <h2 id="resources">Resources</h2>
  <p>
  <ul>
  <li><a href="#research-centers">Research Centers</a></li>
  <li><a href="#related">Related Conferences and Journals</a></li>
  <li><a href="#datasets">Datasets</a></li>
  <li><a href="#educational-materials">Educational Materials</a></li>
  <!-- <li><a href="#related-texts">Related Texts</a></li> -->
  <li><a href="#software-tools">Software Tools</a></li>
  </ul>
  </br>
  </p>

  <h3 id="academic-groups">Overview</h3>
  <p>The following is a non-exhaustive list of content relevant to the ISMIR community,
  submitted by its members. Keep in mind that it is provided in good faith and a result
  of user submissions, and therefore may not be representative of the full reach of ISMIR.
  </p>
  <p>
  See something missing / in error?
  <ul>
  <li><a href="https://docs.google.com/forms/d/1vYIfoRBI0slDL2ep_uuAweuLIHSU2lY6o8qh-XPMN5I/viewform" target="_blank">Contributions</a></li>
  <li><a href="mailto:webmaster@ismir.net">Corrections</a></li>
  </ul>
  </br>
  </p>

  <h3 id="research-centers">Research Centers</h3>
  <table style="width:100%">
  <tr>
    <td><b>Group / Description</b></td>
    <td><b>Location</b></td>
  </tr>
  <tr>
    <td><a href="http://marl.smusic.nyu.edu">Music and Audio Research Laboratory at New York University</a>
    </br>Doctoral and masters programs in music technology in the heart of New York City. Main research areas
       include MIR, Immersive Audio, Music Cognition and Interactive Systems.</li>
    </td>
    <td>US</td>
  </tr>
  <tr>
    <td><a href="http://mir.dei.uc.pt/">MIR Group at the University of Coimbra</a></td>
    <td>PT</td>
  </tr>
  <tr>
    <td><a href="http://www.ifs.tuwien.ac.at/mir">Music Information Retrieval Lab at Vienna University of Technology</a></td>
    <td>AT</td>
  </tr>
  <tr>
    <td><a href="http://www.gtcmt.gatech.edu/">Music Technology at Georgia Tech</a></td>
    <td>US</td>
  </tr>
  <tr>
    <td><a href="http://mi.soi.city.ac.uk/">Music Informatics Research Group at City University London</a></td>
    <td>UK</td>
  </tr>
  <tr>
    <td><a href="http://www.algomus.fr/">Algomus</a>
    </br>Research lab on computational music analysis, focusing on large-scale analysis of scores.</td>
    <td>FR</td>
  </tr>
  <tr>
    <td><a href="http://www.cp.jku.at">Department of Computational Perception of the Johannes Kepler University Linz</a> </td>
    <td>AT</td>
  </tr>
  <tr>
    <td><a href="http://c4dm.eecs.qmul.ac.uk/">Centre for Digital Music (C4DM) at Queen Mary University of London</a>
    </br>C4DM is a world-leading multidisciplinary research group in the field
    of music and audio technology. Research ranges from record/replay equipment to the
    simulation and synthesis of instruments and voices, acoustic spaces, music
    understanding, delivery and retrieval. With a strong focus on making innovation
    usable, we are ideally placed to work with industry leaders in forging new business
    models for the music industry.</td>
    <td>UK</td>
  </tr>
  <tr>
    <td><a href="http://www.create.aau.dk/audio/">Audio Analysis Lab at Aalborg University</a></td>
    <td>DK</td>
  </tr>
  <tr>
    <td><a href="http://sig-ma.de/">Special Interest Group on Music Analysis</a></td>
    <td>DE</td>
  </tr>
  <tr>
    <td><a href="http://mtg.upf.edu/">Music Technology Group at UPF</a> </br>
    The Music Technology Group (MTG) of the Universitat Pompeu Fabra in
    Barcelona is specialized in sound and music computing. With more than 50
    researchers, the MTG carries out research on topics such as audio signal
    processing, sound and music description, musical interfaces, sound and music
    communities and performance modeling among others.
    </td>
    <td>ES</td>
  </tr>
  <tr>
    <td><a href="http://www.ofai.at/research/impml/index.html">Intelligent Music Processing Group at the Austrian Research Institute for Artificial Intelligence</a></td>
    <td>AT</td>
  </tr>
  <tr>
    <td><a href="http://music.ece.drexel.edu">Music and Entertainment Technology Laboratory (MET-lab) at Drexel</a></br>
    The Music and Entertainment Technology Laboratory (MET-lab) is devoted
    to research in digital media technologies that will shape the future of entertainment.
    MET-lab's primary research focus encompasses several areas: music information
    retrieval, music production technology, new musical interfaces, and musical
    humanoid robotics. The lab also emphasizes K-12 outreach and hosts Summer Music
    Technology, a one-week experience based educational curriculum for high school students.</td>
    <td>US</td>
  </tr>
  <tr>
    <td><a href="http://mue.music.miami.edu/">Music Engineering at the University of Miami</a></td>
    <td>US</td>
  </tr>
  <tr>
    <td><a href="http://www.cirmmt.org/">The Centre of Interdisciplinary Research in Music Media and Technology (CIRMMT) at McGill</a></td>
    <td>CA</td>
  </tr>
  <tr>
    <td><a href="http://www.ircam.fr/">Institut de Recherche et Coordination Acoustique / Musique (IRCAM)</a></td>
    <td>FR</td>
  </tr>
  </table>


  </ul>

  <h3 id="datasets">Datasets</h3>
  <ul>
  <li>[<a href="http://labrosa.ee.columbia.edu/millionsong/">link</a>] Primary resource for the Million Song Dataset</li>
  <li>[<a href="http://mtg.upf.edu/download/datasets">link</a>] Various datasets hosted by the MTG.</li>
  <li>[<a href="http://www.ifs.tuwien.ac.at/mir/msd/">link</a>] Alternative resource for the Million Song Dataset: Feature Sets and Benchmark splits.</li>
    <li>[<a href="http://ddmal.music.mcgill.ca/billboard">link</a>] Home page of the McGill Billboard annotations, containing time-aligned chord annotations and structural analyses of a randomised sample of over 1000 songs
  from the American Billboard Hot 100 charts between 1958 and 1991.</li>
  <li>[<a href="http://www.cs.rhodes.edu/~kirlinp/schenker/">link</a>] A dataset of MusicXML excerpts and corresponding Schenkerian analyses in a computer-readable format.</li>
  <li>[<a href="http://algomus.fr/truth/">link</a>] Truth data for computational music analysis. Now contains a dataset of ground truth structures for fugues.</li>
  <li>[<a href="http://www.cp.jku.at/datasets/MMTD/">link</a>] The "Million Musical Tweets Dataset" (MMTD) contains listening histories inferred from microblogs.
  Each listening event identified via twitter-id and user-id is annotated with temporal (date, time, weekday, timezone), spatial (longitude, latitude, continent, country,
  county, state, city), and contextual (information on the country) information. In addition, pointers to artist and track are provided as a matter of course.</li>
  <li>[<a href="http://www.cp.jku.at/datasets/musicmicro/index.html">link</a>] The "MusicMicro 11.11-09.12" data set contains listening histories inferred from microblogs. Each listening event identified via twitter-id and
  user-id is annotated with temporal (month and weekday) and spatial (longitude, latitude, country, and city) information. In addition, pointers to artist and track
  are provided as a matter of course.</li>
  <li>[<a href="http://www.cp.jku.at/datasets/musiclef/index.html">link</a>] The MusiClef 2012 - Multimodal Music Data Set provides editorial metadata, various audio features, user tags, web pages, and expert labels
  on a set of 1355 popular songs. It was used in the MusiClef 2012 <a href="http://multimediaeval.org/mediaeval2012/newtasks/music2012/index.html">Evaluation Campaign</a>.</li>
  <li>[<a href="http://imi.aau.dk/~bst/software/GTZANindex.txt">link</a>] Index of contents of the GTZAN dataset.</li>
  <li>[<a href="http://media.aau.dk/null_space_pursuits/2014/02/faults-in-the-latin-music-database.html">link</a>] List of replicas found in the Latin Music Database.</li>
  <li>[<a href="http://media.aau.dk/null_space_pursuits/2014/01/ballroom-dataset.html">link</a>] List of replicas found in the Ballroom dataset.</li>
  </ul>

<!--   <h3 id="demos">Demos</h3>
  <ul>
  <li>stuff</li>
  </ul> -->

  <h3 id="educational-materials">Educational Materials</h3>
  <ul>
  <li>[<a href="http://www.AudioContentAnalysis.org">link</a>] Matlab code for feature extraction, pitch tracking, key detection, onset detection,
  and links to data sets and MIR-related software projects.
  </li>
  <li>[<a href="">link</a>] A centralized collection of teaching resources related to Music Information Retrieval. It is addressed to teachers and
  students interested on these technologies from an educational point of view. Current resources include the following: a list of courses related to
  MIR in different levels, institutions and countries; a collaborative (small) list of teaching materials, such as exercises, musical examples, code;
  and a list of datasets and ground truth annotations.</li>
  <!-- <li>[<a href="">link</a>]  </li> -->
  </ul>

  <h3 id="software-tools">Software Tools</h3>
  <ul>
  <li>[<a href="http://jmir.sourceforge.net">link</a>] jMIR is an open-source software suite implemented in Java for use in music classification research.
  It can be used to study music in both audio and symbolic formats, as well as mine cultural information from the web and manage music collections. jMIR
  includes software for extracting features, applying machine learning algorithms, mining metadata and analyzing metadata.</li>
  <li>[<a href="http://essentia.upf.edu/">link</a>] Essentia is an open-source C++ library for audio analysis and audio-based music information retrieval
  released under the Affero GPLv3 license (also available under proprietary license upon request) which has been developed by the Music Technology Group in
  Universitat Pompeu Fabra. Essentia was awarded with the Open-Source Competition of ACM Multimedia in 2013.</li>
  <li>[<a href="https://github.com/bmcfee/librosa/">link</a>] LibRosa is a python package for music and audio processing.</li>
  </ul>

</div>

<div id="footer">
Copyright &copy; ISMIR, 2014
</div>
</div>
</div>
</body>
</html>
